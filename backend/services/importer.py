"""
ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ã‚¿ãƒ¼
==================
CSVãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
"""
import csv
import json
from pathlib import Path
from urllib.parse import urlparse
from typing import Optional

from .config import settings
from .database import db


def get_article_slug(url: str) -> str:
    """URLã‹ã‚‰è¨˜äº‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‚’æŠ½å‡º: username_articleid"""
    parsed = urlparse(url)
    path_parts = parsed.path.strip("/").split("/")
    if len(path_parts) >= 3 and path_parts[1] == "articles":
        return f"{path_parts[0]}_{path_parts[2]}"
    return None


def find_article_dir(url: str, edition: int) -> Optional[Path]:
    """æŒ‡å®šã•ã‚ŒãŸURLã®è¨˜äº‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢"""
    slug = get_article_slug(url)
    if not slug:
        return None
    article_dir = settings.DATA_DIR / "articles" / str(edition) / slug
    if article_dir.exists():
        return article_dir
    return None


def load_article_content(article_dir: Path) -> Optional[str]:
    """è¨˜äº‹Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’èª­ã¿è¾¼ã¿"""
    md_path = article_dir / "article.md"
    if md_path.exists():
        return md_path.read_text(encoding="utf-8")
    return None


def import_csv(csv_path: Path, edition: int, load_articles: bool = True) -> dict:
    """
    å˜ä¸€ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    
    Args:
        csv_path: ã‚¨ãƒ³ãƒªãƒƒãƒã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ‘ã‚¹
        edition: ãƒãƒƒã‚«ã‚½ãƒ³å›æ•°ï¼ˆ1, 2, 3ï¼‰
        load_articles: ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’èª­ã¿è¾¼ã‚€ã‹
    
    Returns:
        ä»¶æ•°ã‚’å«ã‚€çµ±è¨ˆè¾æ›¸
    """
    stats = {"total": 0, "imported": 0, "skipped": 0, "articles_loaded": 0}
    
    with open(csv_path, encoding="utf-8") as f:
        reader = csv.DictReader(f)
        rows = list(reader)
    
    stats["total"] = len(rows)
    
    with db.get_connection() as conn:
        for row in rows:
            url = row.get("URL", "")
            if not url:
                stats["skipped"] += 1
                continue
            
            # æ—¢å­˜ã‹ãƒã‚§ãƒƒã‚¯
            existing = conn.execute(
                "SELECT id FROM projects WHERE url = ?", (url,)
            ).fetchone()
            
            if existing:
                stats["skipped"] += 1
                continue
            
            # ä½œè€…ã‚¿ã‚¤ãƒ—ã‚’ãƒ‘ãƒ¼ã‚¹
            author_raw = row.get("Author/Team", "")
            if "ãƒãƒ¼ãƒ :" in author_raw or "ãƒãƒ¼ãƒ : " in author_raw:
                author_type = "ãƒãƒ¼ãƒ "
                author_name = author_raw.replace("ãƒãƒ¼ãƒ : ", "").replace("ãƒãƒ¼ãƒ :", "")
            else:
                author_type = "å€‹äºº"
                author_name = author_raw
            
            # è¨˜äº‹ã‚¹ãƒ©ãƒƒã‚°ã¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
            article_slug = get_article_slug(url)
            content_raw = None
            
            if load_articles:
                article_dir = find_article_dir(url, edition)
                if article_dir:
                    content_raw = load_article_content(article_dir)
                    if content_raw:
                        stats["articles_loaded"] += 1
            
            # æ•°å€¤ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãƒ‘ãƒ¼ã‚¹
            def safe_int(val, default=0):
                if val is None or val == "":
                    return default
                try:
                    return int(val)
                except (ValueError, TypeError):
                    return default
            
            def safe_bool(val):
                if isinstance(val, bool):
                    return val
                return str(val).lower() == "true"
            
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æŒ¿å…¥
            conn.execute("""
                INSERT INTO projects (
                    hackathon_id, no, project_name, url, author_type, author_name,
                    description, content_raw, content_summary, likes, bookmarks, accessible, http_status,
                    is_winner, award_name, award_comment, is_final_pitch, article_slug,
                    tech_stacks, tags
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                edition,
                safe_int(row.get("No")),
                row.get("Project Name", "Unknown"),
                url,
                author_type,
                author_name,
                row.get("Description", ""),
                content_raw,
                row.get("ContentSummary") or None,  # æ–°è¦: è¦ç´„
                safe_int(row.get("Likes")),
                safe_int(row.get("Bookmarks")),
                1 if safe_bool(row.get("Accessible", True)) else 0,
                safe_int(row.get("Status")) if row.get("Status", "").isdigit() else None,
                1 if safe_bool(row.get("IsWinner", False)) else 0,
                row.get("AwardName") or None,
                row.get("AwardComment") or None,
                1 if safe_bool(row.get("IsFinalPitch", False)) else 0,
                article_slug,
                row.get("TechStacks") or None,  # æ–°è¦: æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯
                row.get("Tags") or None,  # æ–°è¦: ã‚¿ã‚°
            ))
            stats["imported"] += 1
        
        conn.commit()
    
    return stats


def import_all_data(load_articles: bool = True) -> dict:
    """
    ã™ã¹ã¦ã®ãƒãƒƒã‚«ã‚½ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    
    Returns:
        çµ±åˆã•ã‚ŒãŸçµ±è¨ˆ
    """
    print("\nğŸš€ ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’é–‹å§‹...")
    print("=" * 50)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–
    db.init_db()
    
    total_stats = {"total": 0, "imported": 0, "skipped": 0, "articles_loaded": 0}
    
    for edition in [1, 2, 3]:
        csv_path = settings.DATA_DIR / "csv" / f"{edition}_hackathon_enriched.csv"
        
        if not csv_path.exists():
            print(f"âš ï¸  CSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
            continue
        
        print(f"\nğŸ“ ç¬¬{edition}å›ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­: {csv_path.name}")
        
        stats = import_csv(csv_path, edition, load_articles)
        
        for key in total_stats:
            total_stats[key] += stats[key]
        
        print(f"   âœ… ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {stats['imported']}")
        print(f"   â­ï¸  ã‚¹ã‚­ãƒƒãƒ—: {stats['skipped']}")
        if load_articles:
            print(f"   ğŸ“„ è¨˜äº‹: {stats['articles_loaded']}")
    
    print("\n" + "=" * 50)
    print("ğŸ“Š ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†:")
    print(f"   ç·ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°: {total_stats['total']}")
    print(f"   ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¸ˆã¿: {total_stats['imported']}")
    print(f"   ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé‡è¤‡ï¼‰: {total_stats['skipped']}")
    print(f"   èª­è¾¼ã¿è¨˜äº‹æ•°: {total_stats['articles_loaded']}")
    
    return total_stats


if __name__ == "__main__":
    import_all_data()
