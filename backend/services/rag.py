"""
RAG (Retrieval Augmented Generation) ã‚µãƒ¼ãƒ“ã‚¹
==============================================
ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ChromaDBã€åŸ‹ã‚è¾¼ã¿ã¨ãƒãƒ£ãƒƒãƒˆã«Azure OpenAIã‚’ä½¿ç”¨
"""
from pathlib import Path
from typing import Optional

from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter

from .config import settings
from .database import db


# æ—¥æœ¬èªRAGãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
RAG_PROMPT_JA = PromptTemplate(
    template="""ã‚ãªãŸã¯Zenn AI Agent Hackathonã®ä½œå“ã«è©³ã—ã„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ¤œç´¢ã•ã‚ŒãŸé–¢é€£è¨˜äº‹ï¼‰ã‚’å‚è€ƒã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
{context}

è³ªå•: {question}

å›ç­”ï¼ˆå…·ä½“çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’æŒ™ã’ãªãŒã‚‰èª¬æ˜ã—ã¦ãã ã•ã„ï¼‰:""",
    input_variables=["context", "question"]
)


class RAGService:
    """ãƒãƒƒã‚«ã‚½ãƒ³ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¯ã‚¨ãƒªç”¨RAGã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        settings.ensure_dirs()
        
        # APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        if not settings.AZURE_OPENAI_API_KEY:
            raise ValueError("AZURE_OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        
        # åŸ‹ã‚è¾¼ã¿ã®åˆæœŸåŒ–
        self.embeddings = AzureOpenAIEmbeddings(
            azure_deployment=settings.AZURE_EMBEDDING_DEPLOYMENT,
            openai_api_key=settings.AZURE_OPENAI_API_KEY,
            azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
            api_version=settings.AZURE_OPENAI_API_VERSION
        )
        
        # LLMã®åˆæœŸåŒ–
        self.llm = AzureChatOpenAI(
            azure_deployment=settings.AZURE_CHAT_DEPLOYMENT,
            openai_api_key=settings.AZURE_OPENAI_API_KEY,
            azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
            api_version=settings.AZURE_OPENAI_API_VERSION
        )
        
        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®åˆæœŸåŒ–
        self.vectorstore = Chroma(
            persist_directory=str(settings.CHROMA_DB_PATH),
            embedding_function=self.embeddings,
            collection_name="hackathon_projects"
        )
        
        self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": 5})
    
    def index_projects(self, edition: Optional[int] = None) -> int:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        
        Args:
            edition: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ãƒãƒƒã‚«ã‚½ãƒ³å›ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
        Returns:
            ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°
        """
        print("ğŸ”„ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ChromaDBã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸­...")
        
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å«ã‚€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
        projects = db.get_projects(edition=edition, limit=1000)
        
        # é•·ã„è¨˜äº‹ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¹ãƒ—ãƒªãƒƒã‚¿ãƒ¼
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=2000,
            chunk_overlap=200,
            separators=["\n\n", "\n", "ã€‚", ".", " "]
        )
        
        documents = []
        for project in projects:
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            content = project.get("content_raw") or project.get("description") or ""
            if not content or len(content) < 50:
                continue
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            metadata = {
                "project_id": project["id"],
                "project_name": project["project_name"],
                "url": project["url"],
                "edition": project["hackathon_id"],
                "author_name": project["author_name"],
                "likes": project["likes"],
                "is_winner": bool(project["is_winner"]),
                "award_name": project.get("award_name") or "",
            }
            
            # é•·ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†å‰²
            chunks = text_splitter.split_text(content)
            
            for i, chunk in enumerate(chunks):
                doc = Document(
                    page_content=chunk,
                    metadata={**metadata, "chunk_index": i}
                )
                documents.append(doc)
        
        if documents:
            # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«è¿½åŠ 
            self.vectorstore.add_documents(documents)
            print(f"âœ… {len(projects)}ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰{len(documents)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã—ã¾ã—ãŸ")
        else:
            print("âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
        
        return len(documents)
    
    def query(self, question: str) -> dict:
        """
        RAGã‚·ã‚¹ãƒ†ãƒ ã«ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ
        
        Args:
            question: æ—¥æœ¬èªã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•
        
        Returns:
            å›ç­”ã¨ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å«ã‚€è¾æ›¸
        """
        # é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
        docs = self.retriever.invoke(question)
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        context = "\n\n---\n\n".join([doc.page_content for doc in docs])
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        prompt = RAG_PROMPT_JA.format(context=context, question=question)
        
        # LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—
        response = self.llm.invoke(prompt)
        
        sources = []
        for doc in docs:
            sources.append({
                "project_name": doc.metadata.get("project_name"),
                "url": doc.metadata.get("url"),
                "edition": doc.metadata.get("edition"),
                "is_winner": doc.metadata.get("is_winner"),
            })
        
        # URLã§é‡è¤‡é™¤å»
        seen_urls = set()
        unique_sources = []
        for src in sources:
            if src["url"] not in seen_urls:
                seen_urls.add(src["url"])
                unique_sources.append(src)
        
        return {
            "answer": response.content,
            "sources": unique_sources
        }
    
    def similarity_search(self, query: str, k: int = 5) -> list[dict]:
        """
        LLMç”Ÿæˆãªã—ã®é¡ä¼¼åº¦æ¤œç´¢ã‚’å®Ÿè¡Œ
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            k: çµæœæ•°
        
        Returns:
            ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãã®ãƒãƒƒãƒã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆ
        """
        docs = self.vectorstore.similarity_search(query, k=k)
        
        results = []
        for doc in docs:
            results.append({
                "content": doc.page_content[:500],
                "metadata": doc.metadata
            })
        
        return results


# é…å»¶åˆæœŸåŒ–
_rag_service: Optional[RAGService] = None

def get_rag_service() -> RAGService:
    """RAGã‚µãƒ¼ãƒ“ã‚¹ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã®å–å¾—ã¾ãŸã¯ä½œæˆ"""
    global _rag_service
    if _rag_service is None:
        _rag_service = RAGService()
    return _rag_service
