---
title: "創造性を育む音楽教育ツール FlatJam"
url: "https://zenn.dev/nayus/articles/82e226cac28e53"
author: ""
published_at: "2025-06-30T13:04:44+00:00"
scraped_at: "2025-12-14T13:20:44.253864"
---

#  デモ動画 (3分)

<https://youtu.be/Z4nfKuNFrVU>

#  1\. 背景・課題

教育現場におけるAI導入が進んでいます。児童や生徒がタブレットで問題を解くと、AIが本人の理解度や習熟度に合わせて、次の問題を提示する。一人ひとりに合った学習内容が提案されることで、学習効率が向上するのです。

算数や英語など、いわゆる主要教科と呼ばれる科目においては、AI導入事例は増加しています。これは言語能力や論理的思考能力、記憶力を鍛える科目と、こうしたAIによる個別化学習の相性が良いためであると言えるでしょう。

一方で、音楽や美術など、実技教科と呼ばれる科目におけるAIの導入事例は乏しく、未だ従来の画一的な授業・カリキュラムによる指導が大半を占めています。このような画一的な指導では、『【音楽編】中学校学習指導要綱』内の教科の目標にある、「音楽表現を創意工夫することや、音楽のよさや美しさを味わって聴くことができるように」なる指導は容易ではないでしょう。

今回開発したFlatJamは、実技教科のうち、音楽教育に着目し、作曲を通して一人ひとりが自分らしい音楽表現をし、創造性を解き放つことを目指したプロダクトです。AI Agentと対話しながら、自分の思いや考えていることを音として紡ぐ体験を通して、自身の感性に音楽的なラベリングをしたり、作曲を自己表現の一手段として認識できるようになることを目指します。

#  2\. FlatJamとは

FlatJamは、学校における音楽教育現場の指導者と生徒をターゲットとして、作曲を通して生徒一人ひとりの創造性が発揮される授業づくりを目指します。  
音楽指導者は、音楽授業を通して生徒の創造性を引き出したいと考えているものの、生徒一人ひとりの考えや趣向を適切に理解し、適切な指導やアドバイスを行うことは労力面から難しく、従来の画一的な音楽指導が中心となっている現状に不満を抱いています。一方、生徒は自身が興味をいだいている流行りのアーティストの曲を聴いたり、カラオケで歌ったりする音楽に対しては肯定的ですが、画一的で工夫の余地が限られている音楽授業に対しては食傷気味です。  
このように、生徒一人ひとりの創造性を引き出したい指導者と、自己の主張や表現が可能な音楽を求めている学習者との間で、FlatJamはその威力を発揮します。

![](images/img_000.png)  
FlatJamは創造的に作曲を行うことができる音楽教育ツールです。ユーザー（生徒）が自らの思考や好みを自然言語で入力すると、入力された言葉に合った音楽的な知見や技法が、セレンディピティ欄に提案され、その中から自らのアイデアに最も近い知見や技法を取り入れながら曲を作成することが可能です。  
これにより、生徒一人ひとりが自らの思考を音として表現する機会を、一人ひとりに合った個別最適化されたAI Agentとの対話を通して獲得することができるのです。

ここでのポイントは、AIが自動で曲を生成するのではなく、あくまでAIは知見や技法の提案を行い、その提案された中からユーザーが吟味を行い、ユーザーの意思決定によって曲が作成されるという過程を経ることです。昨今はユーザーがプロンプトを入力すると曲を完全に自動で生成する「作曲AI」なるものも登場していますが、創造性の解放という観点においては、自ら候補を吟味し、選択するという、その人の思いや魂がこもった制作プロセスであることが肝要です。創造性の解放にあたっては、制作プロセスの主導権はAIにではなく、人間側が握っておく必要があるのです。

FlatJamは単純にユーザーが入力したプロンプトに対して、適切な曲をAIが選択して生成するのではなく、適切な知見や技法の候補を提示し、人間がそれを吟味し、選択して曲を作成していきます。これこそが、音楽（特に作曲）における創造性の解放において最重要な要素であると考えます。

![](images/img_001.png)

#  3\. 機能

##  3.1 UX機能要件

今回は、「セレンディピティ」を次のように定義しました。

**「セレンディピティ」** : 音楽創作の知見や技法を、文化的背景と共にまとめたもの

これをユーザーの表現したい想いの文脈に沿って提示するように設計しました。

「セレンディピティ」を伴って創造性を育む創作プロセスを達成するために、下記を要件としました。

  * 学習者(ユーザー)の創作の文脈をリアルタイムで解析する
  * 学習者の想いに合った先人の知恵や技法などを、選択肢の候補として提示し、セレンディピティとの出逢いを提供する 
    * ただし、あくまで選択するのは学習者本人であり、押し付けにならないように候補としての提示とする
  * 学習者が自分の手で、候補を試し、感性に照らして吟味することができる
  * 選び取った選択肢を、入力し自分の表現ができる

これらを実現するために、作曲ユーザーインターフェースとセレンディピティシステムを構築しました。

##  3.2 ユーザーインターフェース

画面は4つの部分から構成しました。  
既存のDAWの画面を参考にしつつ設計を行いました。しかし、既存のDAWは多機能すぎて、どこから手をつけていいか分からなくなってしまいます。  
そこで、画面の右側に、作曲メモという気軽に入力できる欄を設けて、ここへ入力を行いながら楽曲のイメージを膨らませていく形式を取りました。  
作曲メモや、トラックの追加を起点にして、セレンディピティの提案が行われるように設計しました。

![](images/img_002.png)

####  Editor Section（左上）

  * **エディター** : トラックに音を入力し、複数のトラックを重ねていくことができる
  * **トラックタイプ** : 
    * Sequencer: ステップシーケンサートラック（4拍 × 8小節の32セル） 
      * セル内にメロディや和音を入力することができる
    * Melody: メロディトラック（MIDI） 
      * メロディをリアルタイム入力できる
    * Chord: 和音トラック（MIDI） 
      * 和音をリアルタイム入力できる
    * Prompt: AI生成トラック（Lyria Realtime）

####  Controller Section（左下）

  * **再生制御** : 再生・停止・録音ON/OFFボタン・メトロノーム 
    * 8小節のループで再生
    * Melody or Chordトラックを選択して、録音をONにした状態で再生すると、リアルタイム録音が可能
  * **楽曲設定** : テンポ・キー
  * **バーチャルキーボード** : PC/タッチ両対応の特殊配列キーボード 
    * ParoTone配列を採用。PCのキーボードを使って、**簡単に左手で和音 + 右手でメロディ** が弾ける配列
    * キーボードの「1〜0、Q〜P、A〜;」の3段に対応しており、簡単に自分の手で音を試すことができるようになる

####  Sidebar Section（右上）

  * **作曲メモ** : 創作のメモを書き溜める場所 
    * 作曲メモの入力がフォーカスアウトしたタイミングで、**セレンディピティの更新が自動的に回る**
  * **Wiki** : セレンディピティの一覧表示

####  Serendipity Section（右下）

  * **セレンディピティ表示** : AIが文脈に応じて提示 
    * 「コード」「メロディ」「プロンプト」などのジャンルごとにボタンが表示される
    * ボタンを押すと、Sidebar Section > Wiki にセレンディピティの内容が表示される
    * ユーザーに過度に誘導を行ってしまうと、ユーザー自身の自発的な創作に対して阻害要因となってしまう懸念があった。そのため、ヒントを与えるボタンのみが表示されるようにして、内容はクリックをした時に初めてWikiで見られるようにした

##  3.3 システムアーキテクチャ

![](images/img_003.png)

  * フロントエンド 
    * Flutterで構築
    * Webビルドを行い、Firebase Hosting でデプロイ
    * Music Context情報を管理する 
      * 作曲メモ
      * トラック情報
      * Tempo、Key
    * 作曲 (DAW) 機能を有し、マルチトラックで作曲ができる
  * バックエンド 
    * Cloud Run Functions でPython環境をホスト 
      * フロントからMusic Contextを伴ったHTTP Requestを受け取り、セレンディピティの候補を返す
    * Lyria (音楽生成AI) 
      * トラックを部分的にAI生成で作成できるようにするために実装
      * AIで曲全体を丸ごと出力するのではなく、部分的にバックの音を足すようにできることを想定。学習者が自分の中のボキャブラリーを増やしていくたびに、音が増やせるようになっていく設計
  * データベース 
    * BigQuery 
      * セレンディピティのデータベースを格納 (後述)

##  3.4 セレンディピティシステム

###  セレンディピティデータベースの構築

####  Deep Researchによる音楽知識の体系化

  * **音楽技法の網羅的収集** : Deep Research機能を活用し、作曲技法・音楽理論を体系的に収集
  * **3つのカテゴリー分類** : 
    * **コード進行** (chord): 王道進行、カノン進行など、実際の楽曲で使用されるパターン
    * **メロディ技法** (melody): ペンタトニックスケール、メロディの反復など
    * **AI生成プロンプト** (prompt): ジャンル・楽器・雰囲気を指定する英語プロンプト
  * **ファクトチェック** : 音楽に詳しいメンバーが全データを検証し、誤情報を排除・修正を行った。そのため、出力される結果の正確性は担保されている
  * **実例との紐付け** : 各技法に代表的な楽曲例を明記（例：王道進行→「夜に駆ける」サビ）

####  データベース構造

![](images/img_004.png)

  * type: chord, melody, promptの3種類
  * title: セレンディピティをWikiに表示する時のタイトル
  * description: 詳細な背景知識等の説明
  * how_to_play: ユーザーが実際に弾こうとした時の演奏方法
  * tag: 検索用のタグ

###  AIレコメンドシステムの実装

####  技術スタック

  * **Cloud Run Functions** : Python環境をホストし、HTTPリクエストで稼働
  * **Gemini** : コンテキスト理解
  * **BigQuery** : 高速な楽曲データベース検索
  * **REST API** : POST `/suggest_music_info` エンドポイント

####  レコメンドアルゴリズム

  1. **コンテキスト解析**

     * フロントエンドから楽曲情報（作曲メモ、MIDI情報）を受信
     * Gemini APIで自然言語処理し、音楽的文脈を理解
  2. **タグ抽出システム**

     * 事前定義タグから最大7つを自動選択
     * ジャンル（jpop, hiphop等）、楽器（guitar, drums等）、感情（nostalgic, 元気等）
     * Temperature=0.7で適度な創造性を確保
  3. **セレンディピティ検索**
         
         SELECT serendipity_id, type, title, description, how_to_play
         FROM `flatjam.sample_data.music_info_db`
         WHERE tag LIKE '%{extracted_tag}%' ...
         

  4. **レスポンス生成**

     * 関連度の高い知見・技法を「セレンディピティ」として返却
     * 各技法に「演奏方法」として学習者がどのように試せば良いかを明示する。これにより、学習者が自分の手で試し、感性で吟味し、選び取ることを支援する

#  4\. おわりに: 創造性を育む

作曲経験のない方々に実際にFlatJamでの作曲を体験してもらいました。

![](images/img_005.jpg)

Nさん「1回自分の曲は作ってみたいと思っていたが、無理だろうなと思っていた。FlatJamなら簡単にできた」  
Wさん「試しにやってみたのが自分のインスピレーションや感性と合った時に、あとは自己流でできる。短いながら1つ自分の曲ができる」

試した方々は、最初はきらきら星や自分の好きな曲のコード進行をなぞるところから出発し、自分が納得するまで自分の手で試す中で、各々の感性にフィットするものが見つかっていっていました。  
次第に、自分の手でメロディを奏でてリアルタイム入力を行って、曲が仕上がっていきました。

セレンディピティを提供することで、感情や想いを外に表すための表現手段を広げる手助けができます。

FlatJamは創造性を育む音楽教育をサポートします。
